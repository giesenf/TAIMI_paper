{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXADmR8s7wQP"
      },
      "outputs": [],
      "source": [
        "#!pip install torch\n",
        "#!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t16_UILyR7d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as transForm\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MvkiottaRgp"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('/content/pack.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu1Aeidq2i9O",
        "outputId": "3ce89354-1480-46ab-b22d-9167b36b555b"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqVgxcbq2o9I"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/pack/processed_data/ct_256'\n",
        "#data_path = '/content/drive/My Drive/Imperial - AI MSc/Medical Imaging/pack.zip'\n",
        "#file_list = os.listdir(data_path)\n",
        "#print(file_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEcXXYKNJR4b",
        "outputId": "81ebd692-399a-4112-b9e5-a4960e898e0b"
      },
      "outputs": [],
      "source": [
        "file_list = os.listdir(data_path)\n",
        "print(file_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF1pc6qbPmfj"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u769e6AQ1NYW"
      },
      "source": [
        "# **1. Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eoN5z19EZFb"
      },
      "outputs": [],
      "source": [
        "class SliceAugmentation:\n",
        "    \"\"\"Class-based augmentation for 2D slices with intensity and spatial transforms\"\"\"\n",
        "    def __call__(self, image, label):\n",
        "        # Intensity variations (applied together 50% of the time)\n",
        "        if torch.rand(1) < 0.5:\n",
        "            # Contrast\n",
        "            contrast_factor = torch.FloatTensor(1).uniform_(0.75, 1.25).item()\n",
        "            image = transForm.adjust_contrast(image, contrast_factor)\n",
        "\n",
        "            # Brightness\n",
        "            brightness_factor = torch.FloatTensor(1).uniform_(0.75, 1.25).item()\n",
        "            image = transForm.adjust_brightness(image, brightness_factor)\n",
        "\n",
        "        # Random horizontal flip\n",
        "        if torch.rand(1) < 0.5:\n",
        "            image = transForm.hflip(image)\n",
        "            label = transForm.hflip(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class SingleSliceDataset(Dataset):\n",
        "    \"\"\"Modified dataset with proper 2D augmentations\"\"\"\n",
        "    def __init__(self, root_dir, testing=False, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.testing = testing\n",
        "        self.transform = transform\n",
        "        self.file_list = [f for f in os.listdir(root_dir) if f.endswith('.npz')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = os.path.join(self.root_dir, self.file_list[idx])\n",
        "        slice_data = np.load(file_path)\n",
        "\n",
        "        # Load data and add channel dimension if needed\n",
        "        image = slice_data['image'][np.newaxis]  # Shape [1, H, W]\n",
        "        label = slice_data['label']  # Shape [H, W]\n",
        "\n",
        "        # Convert to tensors first\n",
        "        image_tensor = torch.from_numpy(image).float()\n",
        "        label_tensor = torch.from_numpy(label).long()\n",
        "\n",
        "        # Apply augmentations only during training\n",
        "        if self.transform is not None:\n",
        "            image_tensor, label_tensor = self.transform(image_tensor, label_tensor)\n",
        "\n",
        "        return image_tensor, label_tensor\n",
        "\n",
        "\n",
        "npz_directory_train = data_path + \"/train/npz\"\n",
        "npz_directory_val = data_path + \"/val/npz\"\n",
        "npz_directory_test = data_path+\"/test/npz\"\n",
        "\n",
        "train_transform = SliceAugmentation()\n",
        "train_dataset = SingleSliceDataset(npz_directory_train, transform=train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=12)\n",
        "\n",
        "val_dataset = SingleSliceDataset(npz_directory_val, transform=None)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=12)\n",
        "\n",
        "test_dataset = SingleSliceDataset(npz_directory_test, transform=None)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWgbajHv0eD5"
      },
      "source": [
        "# **2. Implementation for Pure Segmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVUPSNis1Cmj"
      },
      "source": [
        "### 2.1 Model & Loss Functions Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7VA9qr4xD5f"
      },
      "outputs": [],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=8, features=[64, 128, 256, 512, 1024]):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoders = nn.ModuleList()\n",
        "        for feature in features:\n",
        "            self.encoders.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Pooling layers\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
        "\n",
        "        # Decoder\n",
        "        self.upconvs = nn.ModuleList()\n",
        "        self.decoders = nn.ModuleList()\n",
        "        for feature in reversed(features):\n",
        "            self.upconvs.append(nn.ConvTranspose2d(feature * 2, feature, kernel_size=2, stride=2))\n",
        "            self.decoders.append(DoubleConv(feature * 2, feature))\n",
        "\n",
        "        # Final output layer\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        # Encoder path\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Decoder path\n",
        "        skip_connections = skip_connections[::-1]\n",
        "        for i in range(len(self.decoders)):\n",
        "            x = self.upconvs[i](x)\n",
        "            skip_connection = skip_connections[i]\n",
        "            x = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.decoders[i](x)\n",
        "\n",
        "        return self.final_conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl3JAxUkKHnt"
      },
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, num_classes, smooth=1e-7):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # Ensure labels are in [0, num_classes-1]\n",
        "        # Convert targets to one-hot: [B, H, W] -> [B, C, H, W]\n",
        "        num_classes = logits.shape[1]\n",
        "        targets_onehot = F.one_hot(targets, num_classes=self.num_classes).permute(0, 3, 1, 2).float()\n",
        "\n",
        "        # Softmax probabilities\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        # Sum over batch, height, width\n",
        "        dims = (0, 2, 3)\n",
        "        intersection = torch.sum(probs * targets_onehot, dim=dims)\n",
        "        cardinality = torch.sum(probs + targets_onehot, dim=dims)\n",
        "\n",
        "        # Dice score and loss\n",
        "        dice_score = (2. * intersection + self.smooth) / (cardinality + self.smooth)\n",
        "        return 1.0 - dice_score.mean()\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, alpha=0.25):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # Compute focal loss\n",
        "        ce_loss = F.cross_entropy(logits, targets, reduction='none')  # Shape: [B, H, W]\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "class HybridLoss(nn.Module):\n",
        "    def __init__(self, num_classes, dice_w = 1.0, focal_w = 0.0, cross_w = 1.0):\n",
        "        super().__init__()\n",
        "        self.dice = DiceLoss(num_classes)\n",
        "        self.focal = FocalLoss()\n",
        "        self.crosse = nn.CrossEntropyLoss()\n",
        "        self.dice_w = dice_w\n",
        "        self.focal_w = focal_w\n",
        "        self.cross_w = cross_w\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        # Ensure output is [B, 8, 256, 256] and target is [B, 256, 256]\n",
        "        dice_loss = self.dice(output, target)\n",
        "        focal_loss = self.focal(output, target)\n",
        "        crosse_loss = self.crosse(output, target)\n",
        "        return dice_loss*self.dice_w + focal_loss*self.focal_w + crosse_loss*self.cross_w  # Combine losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ5xYoSG04mQ"
      },
      "source": [
        "### 2.2 Training & Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bscAOAd32heD",
        "outputId": "91536652-b8ac-4868-c564-7d3cd74b47be"
      },
      "outputs": [],
      "source": [
        "# Initialize model and loss\n",
        "model_pure = UNet().to(device)\n",
        "criterion = HybridLoss(num_classes=8)\n",
        "optimizer = torch.optim.AdamW(model_pure.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
        "\n",
        "num_epochs=25\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training\n",
        "    model_pure.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model_pure(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_dataset)\n",
        "\n",
        "    # Validation\n",
        "    model_pure.eval()\n",
        "    val_loss = 0.0\n",
        "    dice_score_total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model_pure(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # Calculate softmax probabilities and one-hot encoded labels\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            targets_one_hot = F.one_hot(labels, num_classes=8).permute(0, 3, 1, 2).float()\n",
        "\n",
        "            dims = (0, 2, 3)\n",
        "            intersection = torch.sum(probs * targets_one_hot, dims)\n",
        "            cardinality = torch.sum(probs + targets_one_hot, dims)\n",
        "            dice = (2. * intersection + 1e-7) / (cardinality + 1e-7)\n",
        "            dice_score_total += dice.mean().item() * images.size(0)\n",
        "\n",
        "    val_loss /= len(val_dataset)\n",
        "    val_dice = dice_score_total / len(val_dataset)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}')\n",
        "    print('-'*20)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "# Test Evaluation\n",
        "model_pure.eval()\n",
        "test_loss = 0.0\n",
        "dice_score_total = 0.0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_pure(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Calculate softmax probabilities and one-hot encoded labels\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "        targets_one_hot = F.one_hot(labels, num_classes=8).permute(0, 3, 1, 2).float()\n",
        "\n",
        "        dims = (0, 2, 3)\n",
        "        intersection = torch.sum(probs * targets_one_hot, dims)\n",
        "        cardinality = torch.sum(probs + targets_one_hot, dims)\n",
        "        dice = (2. * intersection + 1e-7) / (cardinality + 1e-7)\n",
        "        dice_score_total += dice.mean().item() * images.size(0)\n",
        "\n",
        "test_loss /= len(test_dataset)\n",
        "test_dice = dice_score_total / len(test_dataset)\n",
        "print(f'Test Loss: {test_loss:.4f} | Test Dice: {test_dice:.4f}')\n",
        "\n",
        "# Save trained model\n",
        "torch.save(model_pure.state_dict(), 'unet_segmentation_trained.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccyud8KFhMyl"
      },
      "source": [
        "# **3. Implementation for Uncertainty-aware Segmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95CCFsSD1hyu"
      },
      "source": [
        "### 3.1 Model & Loss Functions Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcqbeHA3hX9d"
      },
      "outputs": [],
      "source": [
        "class DoubleConvUnc(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, dropout_p=0.2):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_p),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(dropout_p)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNetUncertainity(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=8, features=[64, 128, 256, 512], dropout_p=0.1):\n",
        "        super().__init__()\n",
        "        # Encoder\n",
        "        self.encoders = nn.ModuleList()\n",
        "        for feature in features:\n",
        "            self.encoders.append(DoubleConvUnc(in_channels, feature, dropout_p))\n",
        "            in_channels = feature\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.bottleneck = DoubleConvUnc(features[-1], features[-1]*2, dropout_p)\n",
        "\n",
        "        # Decoder with initialization\n",
        "        self.upconvs = nn.ModuleList()\n",
        "        self.decoders = nn.ModuleList()\n",
        "        for feature in reversed(features):\n",
        "            self.upconvs.append(\n",
        "                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)\n",
        "            )\n",
        "            self.decoders.append(DoubleConvUnc(feature*2, feature, dropout_p))\n",
        "\n",
        "        # Separate heads for logits and variance\n",
        "        self.logits_head = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "        self.var_head = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "        # Initialize variance head to small values\n",
        "        nn.init.normal_(self.var_head.weight, std=0.01)\n",
        "        nn.init.constant_(self.var_head.bias, -5.0)  # softplus(-5) ≈ 0.0067\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "        # Encoder path\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        # Bottleneck\n",
        "        x = self.bottleneck(x)\n",
        "\n",
        "        # Decoder path\n",
        "        for idx in range(len(self.decoders)):\n",
        "            x = self.upconvs[idx](x)\n",
        "            x = torch.cat([x, skip_connections[-(idx+1)]], dim=1)\n",
        "            x = self.decoders[idx](x)\n",
        "\n",
        "        # Output heads\n",
        "        logits = self.logits_head(x)\n",
        "        var = F.softplus(self.var_head(x)) + 1e-7\n",
        "        return logits, var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbZXi5RNhkAH"
      },
      "outputs": [],
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, num_classes, smooth=1e-7):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # Ensure labels are in [0, num_classes-1]\n",
        "        # Convert targets to one-hot: [B, H, W] -> [B, C, H, W]\n",
        "        num_classes = logits.shape[1]\n",
        "        targets_onehot = F.one_hot(targets, num_classes=self.num_classes).permute(0, 3, 1, 2).float()\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "\n",
        "        # Sum over batch, height, width\n",
        "        dims = (0, 2, 3)\n",
        "        intersection = torch.sum(probs * targets_onehot, dim=dims)\n",
        "        cardinality = torch.sum(probs + targets_onehot, dim=dims)\n",
        "\n",
        "        # Dice score and loss\n",
        "        dice_score = (2. * intersection + self.smooth) / (cardinality + self.smooth)\n",
        "        return 1.0 - dice_score.mean()\n",
        "\n",
        "class HybridLossUnc(nn.Module):\n",
        "    def __init__(self, num_classes, dice_w=1.0, focal_w=0.0, cross_w=1.0, var_reg=10.0):\n",
        "        super().__init__()\n",
        "        self.dice = DiceLoss(num_classes)\n",
        "        self.focal = FocalLoss()\n",
        "        self.cross = nn.CrossEntropyLoss()\n",
        "        self.weights = {'dice': dice_w, 'focal': focal_w, 'cross': cross_w}\n",
        "        self.var_reg = var_reg\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        logits, var = output\n",
        "        std = torch.sqrt(var)\n",
        "\n",
        "        # Multi-sample uncertainty estimation (3 samples)\n",
        "        losses = {'dice': 0.0, 'focal': 0.0, 'cross': 0.0}\n",
        "        for _ in range(3):\n",
        "            epsilon = torch.randn_like(logits)\n",
        "            noisy_logits = logits + epsilon * std\n",
        "\n",
        "            losses['dice'] += self.dice(noisy_logits, target)\n",
        "            losses['focal'] += self.focal(noisy_logits, target)\n",
        "            losses['cross'] += self.cross(noisy_logits, target)\n",
        "\n",
        "        # Average losses over samples + clean logits regularization\n",
        "        dice_loss = (losses['dice']/3) + self.dice(logits, target)\n",
        "        focal_loss = losses['focal']/3\n",
        "        cross_loss = losses['cross']/3\n",
        "\n",
        "        # Variance regularization with improved stability\n",
        "        variance_loss = torch.log1p(torch.mean(var))  # Smoother regularization\n",
        "\n",
        "        total_loss = (\n",
        "            dice_loss * self.weights['dice'] +\n",
        "            focal_loss * self.weights['focal'] +\n",
        "            cross_loss * self.weights['cross'] +\n",
        "            variance_loss * self.var_reg\n",
        "        )\n",
        "        return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv9-QuDb1z4x"
      },
      "source": [
        "### 3.2 Training & Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvT_GETPwaQ9"
      },
      "outputs": [],
      "source": [
        "def enable_dropout(model):\n",
        "    \"\"\"Turn on dropout layers while keeping other modules in eval mode\"\"\"\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.Dropout) or isinstance(module, nn.Dropout2d):\n",
        "            module.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbjYfPzNnChC",
        "outputId": "961ffb89-e899-42e9-deb6-045a5d4d9c2f"
      },
      "outputs": [],
      "source": [
        "#model definitions\n",
        "model_unc = UNetUncertainity(in_channels=1, out_channels=8, dropout_p=0.2).to(device)\n",
        "optimizer = torch.optim.AdamW(model_unc.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
        "criterion = HybridLossUnc(num_classes=8, var_reg=10.0)\n",
        "\n",
        "num_epochs=25\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Train\n",
        "    model_unc.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, var = model_unc(images)\n",
        "        loss = criterion((logits, var), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    train_loss /= len(train_dataset)\n",
        "\n",
        "    # Validation\n",
        "    model_unc.eval()\n",
        "    enable_dropout(model_unc)\n",
        "    val_loss = 0.0\n",
        "    dice_score_total = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            logits, var = model_unc(images)\n",
        "\n",
        "            # Loss calculation handles tuple automatically\n",
        "            loss = criterion((logits, var), labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "\n",
        "            # Use only logits for metrics calculation\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            targets_one_hot = F.one_hot(labels, num_classes=8).permute(0, 3, 1, 2).float()\n",
        "\n",
        "            dims = (0, 2, 3)\n",
        "            intersection = torch.sum(probs * targets_one_hot, dim=dims)\n",
        "            cardinality = torch.sum(probs + targets_one_hot, dim=dims)\n",
        "            dice = (2. * intersection + 1e-7) / (cardinality + 1e-7)\n",
        "            dice_score_total += dice.mean().item() * images.size(0)\n",
        "\n",
        "        val_loss /= len(val_dataset)\n",
        "        val_dice = dice_score_total / len(val_dataset)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}')\n",
        "    print('-'*20)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "# Test Evaluation\n",
        "model_unc.eval()\n",
        "enable_dropout(model_unc)\n",
        "test_loss = 0.0\n",
        "test_dice = 0.0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        logits, var = model_unc(images)\n",
        "        loss = criterion((logits, var), labels)\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "\n",
        "        # Calculate Dice for test set\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        targets_one_hot = F.one_hot(labels, num_classes=8).permute(0, 3, 1, 2).float()\n",
        "        intersection = torch.sum(probs * targets_one_hot, dim=(0, 2, 3))\n",
        "        cardinality = torch.sum(probs + targets_one_hot, dim=(0, 2, 3))\n",
        "        dice = (2. * intersection + 1e-7) / (cardinality + 1e-7)\n",
        "        test_dice += dice.mean().item() * images.size(0)\n",
        "\n",
        "test_loss /= len(test_dataset)\n",
        "test_dice /= len(test_dataset)\n",
        "print(f'Test Loss: {test_loss:.4f} | Test Dice: {test_dice:.4f}')\n",
        "\n",
        "# Save trained model\n",
        "torch.save(model_unc.state_dict(), 'unet_uncertainity_trained.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbgIcueQ411r"
      },
      "source": [
        "# **4. Visualisations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH4SSBdDThZq"
      },
      "outputs": [],
      "source": [
        "def visualize_predictions(imgs, lbls, preds, num_samples=16):\n",
        "    \"\"\"\n",
        "    Visualizes test images, ground truth labels, and model predictions.\n",
        "\n",
        "    Args:\n",
        "        imgs: Tensor [B, C, H, W] or [B, H, W] - Input images.\n",
        "        lbls: Tensor [B, H, W] - Ground truth segmentation masks.\n",
        "        preds: Tensor [B, H, W] - Predicted segmentation masks.\n",
        "        num_samples: int - Number of samples to visualize.\n",
        "    \"\"\"\n",
        "    num_samples = min(num_samples, imgs.shape[0])\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        if imgs.dim() == 4:  # If image has channels, convert to grayscale\n",
        "            image_vis = imgs[i].mean(dim=0).cpu().numpy()  # Average over channels\n",
        "        else:\n",
        "            image_vis = imgs[i].cpu().numpy()  # Direct grayscale image\n",
        "\n",
        "        label_vis = lbls[i].cpu().numpy()  # Ground truth mask\n",
        "        pred_vis = preds[i].cpu().numpy()  # Model prediction mask\n",
        "\n",
        "        # Ensure correct shape\n",
        "        if len(image_vis.shape) == 3:  # If still multi-channel, take middle slice\n",
        "            image_vis = image_vis[image_vis.shape[0] // 2]\n",
        "\n",
        "        # Plot Image\n",
        "        axes[i, 0].imshow(image_vis, cmap='gray')\n",
        "        axes[i, 0].set_title(f\"Test Image {i+1}\")\n",
        "        axes[i, 0].axis(\"off\")\n",
        "\n",
        "        # Plot Ground Truth\n",
        "        axes[i, 1].imshow(label_vis, cmap=\"jet\")\n",
        "        axes[i, 1].set_title(f\"Ground Truth {i+1}\")\n",
        "        axes[i, 1].axis(\"off\")\n",
        "\n",
        "        # Plot Prediction\n",
        "        axes[i, 2].imshow(pred_vis, cmap=\"jet\")\n",
        "        axes[i, 2].set_title(f\"Prediction {i+1}\")\n",
        "        axes[i, 2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAYkXHGzTi2N"
      },
      "outputs": [],
      "source": [
        "def plot_segmentations(model, num_batches, double_out=False):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      counter=1\n",
        "      for batch in test_loader:  # Get a batch of test images\n",
        "          images, labels = batch\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "          # Get predictions\n",
        "          if double_out:\n",
        "            logits, _ = model(images)\n",
        "          else:\n",
        "            logits = model(images)\n",
        "\n",
        "          preds = torch.argmax(logits, dim=1)  # Convert logits to class indices\n",
        "\n",
        "          # Visualize results\n",
        "          visualize_predictions(images, labels, preds)\n",
        "\n",
        "          if counter>num_batches:\n",
        "            break\n",
        "\n",
        "          counter+=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGPOq8dF5mJH"
      },
      "source": [
        "### 4.1 Pure Segmentation Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UKMD2Yt848cN",
        "outputId": "d9d40ffa-1a51-4ce1-99dd-24db08c1b10d"
      },
      "outputs": [],
      "source": [
        "plot_segmentations(model_pure, num_batches=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTKI9giM5uKK"
      },
      "source": [
        "### 4.2 Uncertainty-aware Segmentation Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gC8fF1_255jk",
        "outputId": "462c3e2c-d21a-443f-c3e9-c78b3ffa09ef"
      },
      "outputs": [],
      "source": [
        "plot_segmentations(model_unc, num_batches=1, double_out=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ0BY1qfmjuK"
      },
      "source": [
        "### 4.3 Uncertainty-aware Segmentation + Uncertainity Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUwrhGk5Ip4m"
      },
      "outputs": [],
      "source": [
        "def visualize_uncertainties(image, true_mask, pred_mask, aleatoric, epistemic):\n",
        "    \"\"\"\n",
        "    Visualize input image, true segmentation, predicted segmentation,\n",
        "    aleatoric uncertainty, and epistemic uncertainty.\n",
        "    \"\"\"\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(25, 5))\n",
        "\n",
        "    # Use a discrete colormap with 8 discrete colors (for 8 classes)\n",
        "    cmap = plt.get_cmap('tab10', 8)  # 8 discrete colors for classes 0-7\n",
        "    norm = plt.Normalize(vmin=0, vmax=7)\n",
        "\n",
        "    # Input image\n",
        "    axs[0].imshow(image, cmap='gray')\n",
        "    axs[0].set_title('Input Image')\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    # True segmentation\n",
        "    axs[1].imshow(true_mask, cmap=cmap, norm=norm)\n",
        "    axs[1].set_title('True Segmentation')\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    # Predicted segmentation\n",
        "    im = axs[2].imshow(pred_mask, cmap=cmap, norm=norm)\n",
        "    axs[2].set_title('Predicted Segmentation')\n",
        "    axs[2].axis('off')\n",
        "\n",
        "    # Aleatoric uncertainty\n",
        "    a = axs[3].imshow(aleatoric, cmap='viridis')\n",
        "    axs[3].set_title('Aleatoric Uncertainty')\n",
        "    axs[3].axis('off')\n",
        "    plt.colorbar(a, ax=axs[3])\n",
        "\n",
        "    # Epistemic uncertainty\n",
        "    e = axs[4].imshow(epistemic, cmap='viridis')\n",
        "    axs[4].set_title('Epistemic Uncertainty')\n",
        "    axs[4].axis('off')\n",
        "    plt.colorbar(e, ax=axs[4])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def process_single_sample(model, image, true_mask, num_mc_samples=50):\n",
        "    \"\"\"Process a single sample using MC dropout samples to average segmentation.\"\"\"\n",
        "\n",
        "    # Add batch dimension if missing.\n",
        "    if image.dim() == 3:\n",
        "        image = image.unsqueeze(0).to(device)\n",
        "    if true_mask.dim() == 2:\n",
        "        true_mask = true_mask.unsqueeze(0).to(device)\n",
        "\n",
        "    #eval mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      logits_a, aleatoric = model(image)\n",
        "      fake_preds = torch.argmax(logits_a, dim=1).squeeze().cpu().numpy()\n",
        "      class_indices = torch.argmax(logits_a, dim=1)\n",
        "      aleatoric = aleatoric.mean(dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    #eval with dropout\n",
        "    enable_dropout(model)\n",
        "\n",
        "    probs_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_mc_samples):\n",
        "            logits, _ = model(image)\n",
        "            prob = F.softmax(logits, dim=1)  # [1, C, H, W]\n",
        "            probs_predictions.append(prob.cpu())\n",
        "\n",
        "    stacked_predictions = torch.stack(probs_predictions)\n",
        "    stacked_predictions = stacked_predictions.squeeze(1)  # [n_samples, 1, C, H, W] -> [n_samples, C, H, W]\n",
        "    mean_pred = stacked_predictions.mean(dim=0).numpy()     # [C, H, W]\n",
        "    epistimic = stacked_predictions.var(dim=0).mean(dim=0).cpu().numpy()  # [H, W] (avg over classes)\n",
        "\n",
        "    image_np = image.squeeze().cpu().numpy()\n",
        "    true_mask_np = true_mask.squeeze().cpu().numpy()\n",
        "    pred_mask = np.argmax(mean_pred, axis=0)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return image_np, true_mask_np, pred_mask, aleatoric, epistimic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o_ZCtCv86oRX",
        "outputId": "9c518d40-6917-4c8f-a782-bb160c7aa5d0"
      },
      "outputs": [],
      "source": [
        "#visualise the segmentations and uncertainties\n",
        "for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "    for i in range(images.size(0)):\n",
        "        if batch_idx > 0:\n",
        "            break\n",
        "\n",
        "        single_image = images[i].unsqueeze(0).to(device)\n",
        "        single_label = labels[i].unsqueeze(0).to(device)\n",
        "\n",
        "        image_np, true_mask, pred_mask, aleatoric, epistemic = process_single_sample(\n",
        "            model_unc, single_image, single_label, num_mc_samples=50\n",
        "        )\n",
        "\n",
        "        visualize_uncertainties(image_np, true_mask, pred_mask, aleatoric, epistemic)\n",
        "\n",
        "        del single_image, single_label\n",
        "        torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCAFrIVMKwKL"
      },
      "source": [
        "# **5. Calibration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OYGl11bbnIF"
      },
      "source": [
        "### Aleotoric Scaling Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgkLpTNjYAix",
        "outputId": "6d65fd9a-88e2-4201-92ab-df431a08f31c"
      },
      "outputs": [],
      "source": [
        "class CalibratedUNetUncertainty(UNetUncertainity):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.aleatoric_scale = nn.Parameter(torch.ones(1))  # Learnable scale\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits, var = super().forward(x)\n",
        "        return logits, F.softplus(self.aleatoric_scale) * var  # Scaled output\n",
        "\n",
        "\n",
        "# 1. First load the original trained model\n",
        "original_model = UNetUncertainity().to(device)\n",
        "original_model.load_state_dict(torch.load('unet_uncertainity_trained.pth'))\n",
        "\n",
        "# 2. Create calibrated model and copy weights\n",
        "calib_model = CalibratedUNetUncertainty().to(device)\n",
        "\n",
        "# Copy all weights EXCEPT the new aleatoric_scale parameter\n",
        "pretrained_dict = original_model.state_dict()\n",
        "model_dict = calib_model.state_dict()\n",
        "\n",
        "# 1. Filter out unnecessary keys\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "# 2. Overwrite entries in the existing state dict\n",
        "model_dict.update(pretrained_dict)\n",
        "# 3. Load the new state dict\n",
        "calib_model.load_state_dict(model_dict)\n",
        "\n",
        "# Now proceed with calibration\n",
        "for param in calib_model.parameters():\n",
        "    param.requires_grad = False\n",
        "calib_model.aleatoric_scale.requires_grad = True  # Only this will be trained\n",
        "\n",
        "# Calibrate\n",
        "calib_model.eval()\n",
        "optimizer = torch.optim.LBFGS([calib_model.aleatoric_scale], lr=0.01)\n",
        "for _ in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    loss = 0.0\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        logits, var = calib_model(images)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        targets_onehot = F.one_hot(labels, num_classes=8).permute(0,3,1,2).float()\n",
        "        loss += 0.5 * ((probs - targets_onehot).pow(2) / var + torch.log(var)).mean()\n",
        "    loss.backward()\n",
        "    optimizer.step(lambda: loss)\n",
        "\n",
        "print(f\"Aleatoric scale: {F.softplus(calib_model.aleatoric_scale).item():.4f}\")\n",
        "aleotoric_scale = F.softplus(calib_model.aleatoric_scale).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgTpHfiNbh1w"
      },
      "source": [
        "### 5.2 Temperature Scaling Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mcf7I0Mbhbt"
      },
      "outputs": [],
      "source": [
        "class TemperatureScaledModel(nn.Module):\n",
        "    def __init__(self, base_model, temp_init=1.0):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.temperature = nn.Parameter(torch.tensor(temp_init))  # Learnable parameter\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through base model (with aleatoric calibration)\n",
        "        logits, var = self.base_model(x)\n",
        "\n",
        "        # Apply temperature scaling to logits (affects epistemic uncertainty)\n",
        "        scaled_logits = logits / self.temperature\n",
        "        return scaled_logits, var  # Return scaled logits + original aleatoric var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAEuot4vbylC"
      },
      "outputs": [],
      "source": [
        "def calibrate_temperature(model_scaled, val_loader, device):\n",
        "    # Wrap model with temperature parameter\n",
        "    temp_model = TemperatureScaledModel(model_scaled).to(device)\n",
        "    optimizer = torch.optim.LBFGS([temp_model.temperature], lr=0.01, max_iter=50)\n",
        "    criterion = nn.CrossEntropyLoss()  # Only CE used here\n",
        "\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "        total_loss = 0.0\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass with temperature\n",
        "            logits, _ = temp_model(images)  # (var unused in calibration)\n",
        "            loss = criterion(logits, labels)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "        return total_loss\n",
        "\n",
        "    optimizer.step(closure)  # Single call is sufficient\n",
        "\n",
        "    print(f\"Optimal temperature: {temp_model.temperature.item():.4f}\")\n",
        "    return temp_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hep68u9icHt_",
        "outputId": "375b9691-29e0-4430-92ef-2a5b53ab102c"
      },
      "outputs": [],
      "source": [
        "# Calibrate temperature on validation set\n",
        "temp_scaled_model = calibrate_temperature(calib_model, val_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZnd9T9UfZr2"
      },
      "outputs": [],
      "source": [
        "# Save model path\n",
        "torch.save(temp_scaled_model.state_dict(), 'unet_uncertainity_calibrated_trained.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "azNp8kJjfAy_",
        "outputId": "c565d8f4-de7f-41c7-d73a-eb88dbd48190"
      },
      "outputs": [],
      "source": [
        "#visualise the segmentations and uncertainties\n",
        "for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "    for i in range(images.size(0)):\n",
        "        if batch_idx > 0:\n",
        "            break\n",
        "\n",
        "        single_image = images[i].unsqueeze(0).to(device)\n",
        "        single_label = labels[i].unsqueeze(0).to(device)\n",
        "\n",
        "        image_np, true_mask, pred_mask, aleatoric, epistemic = process_single_sample(\n",
        "            temp_scaled_model, single_image, single_label, num_mc_samples=50\n",
        "        )\n",
        "\n",
        "        visualize_uncertainties(image_np, true_mask, pred_mask, aleatoric, epistemic)\n",
        "\n",
        "        del single_image, single_label\n",
        "        torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIkGMZhCd0Or"
      },
      "source": [
        "### 5.3 Calibration Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ud6Y6A6BKzw2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.calibration import calibration_curve\n",
        "from tqdm import tqdm\n",
        "\n",
        "def compute_uncertainties(model, dataloader, device, mc_samples=50):\n",
        "    \"\"\"Compute both types of uncertainties for a dataset.\n",
        "\n",
        "    Aleatoric uncertainty is computed with dropout disabled (deterministic pass),\n",
        "    while epistemic uncertainty is estimated via MC dropout.\n",
        "    \"\"\"\n",
        "    # Set model to evaluation mode (dropout off)\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "    all_aleatoric = []\n",
        "    all_epistemic = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc=\"Computing Uncertainties\"):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # --- Compute aleatoric uncertainty (and logits) with dropout disabled ---\n",
        "            logits_single, aleatoric_single = model(images)\n",
        "            # For segmentation: use softmax on logits from the single pass and get predicted class\n",
        "            probs_single = torch.softmax(logits_single, dim=1)\n",
        "            pred_class = probs_single.argmax(dim=1)\n",
        "            # Gather the aleatoric uncertainty for the predicted class\n",
        "            aleatoric_single = torch.gather(aleatoric_single, 1, pred_class.unsqueeze(1))\n",
        "\n",
        "            # --- Compute epistemic uncertainty via MC dropout ---\n",
        "            # Temporarily enable dropout for MC sampling\n",
        "            enable_dropout(model)\n",
        "            mc_logits = []\n",
        "            for _ in range(mc_samples):\n",
        "                logits_mc, _ = model(images)  # We ignore aleatoric from these passes\n",
        "                mc_logits.append(logits_mc)\n",
        "            mc_logits = torch.stack(mc_logits)  # shape: [mc_samples, B, C, H, W]\n",
        "\n",
        "            # Restore dropout off for subsequent operations\n",
        "            model.eval()\n",
        "\n",
        "            # Compute epistemic uncertainty: variance of probabilities across MC samples\n",
        "            probs_mc = torch.softmax(mc_logits, dim=2)  # softmax over channel dimension\n",
        "            epistemic = probs_mc.var(dim=0).mean(dim=1, keepdim=True)  # shape: [B,1,H,W]\n",
        "\n",
        "            all_logits.append(logits_single)\n",
        "            all_aleatoric.append(aleatoric_single)\n",
        "            all_epistemic.append(epistemic)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    return (\n",
        "        torch.cat(all_logits),\n",
        "        torch.cat(all_aleatoric),\n",
        "        torch.cat(all_epistemic),\n",
        "        torch.cat(all_labels)\n",
        "    )\n",
        "\n",
        "\n",
        "def flatten_segmentation_data(*tensors):\n",
        "    \"\"\"Flatten batch and spatial dimensions\"\"\"\n",
        "    return [tensor.flatten().cpu().numpy() for tensor in tensors]\n",
        "\n",
        "# def calibration_curves(logits, aleatoric, epistemic, labels, n_quantiles=10):\n",
        "#     \"\"\"Plot calibration curves for both uncertainties using quantile binning\"\"\"\n",
        "#     probs = torch.softmax(logits, dim=1)\n",
        "#     pred_classes = probs.argmax(dim=1)\n",
        "#     errors = (pred_classes != labels).float()\n",
        "\n",
        "#     # Flatten all tensors\n",
        "#     prob_flat, error_flat, alea_flat, epi_flat = flatten_segmentation_data(\n",
        "#         probs.max(dim=1)[0], errors, aleatoric.squeeze(), epistemic.squeeze()\n",
        "#     )\n",
        "\n",
        "#     # Common quantile bins based on combined uncertainties\n",
        "#     combined_unc = alea_flat + epi_flat\n",
        "#     quantiles = np.quantile(combined_unc, np.linspace(0, 1, n_quantiles+1))\n",
        "\n",
        "#     # Bin indices for both uncertainties\n",
        "#     alea_bins = np.digitize(alea_flat, quantiles) - 1\n",
        "#     epi_bins = np.digitize(epi_flat, quantiles) - 1\n",
        "\n",
        "#     # Calculate calibration metrics per bin\n",
        "#     alea_acc, alea_conf = [], []\n",
        "#     epi_acc, epi_conf = [], []\n",
        "\n",
        "#     for i in range(n_quantiles):\n",
        "#         # Aleatoric\n",
        "#         alea_mask = (alea_bins == i)\n",
        "#         if alea_mask.sum() > 0:\n",
        "#             alea_acc.append(error_flat[alea_mask].mean())\n",
        "#             alea_conf.append(alea_flat[alea_mask].mean())\n",
        "\n",
        "#         # Epistemic\n",
        "#         epi_mask = (epi_bins == i)\n",
        "#         if epi_mask.sum() > 0:\n",
        "#             epi_acc.append(error_flat[epi_mask].mean())\n",
        "#             epi_conf.append(epi_flat[epi_mask].mean())\n",
        "\n",
        "#     # Plotting\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "#     plt.plot(alea_conf, alea_acc, 'o-', label='Aleatoric')\n",
        "#     plt.plot(epi_conf, epi_acc, 'o-', label='Epistemic')\n",
        "#     plt.plot([0, 1], [0, 1], 'k--', label='Perfect')\n",
        "#     plt.xlabel('Predicted Uncertainty (Quantile Bins)')\n",
        "#     plt.ylabel('Empirical Error Rate')\n",
        "#     plt.title('Uncertainty Calibration Curves')\n",
        "#     plt.legend()\n",
        "#     plt.show()\n",
        "\n",
        "def uncertainty_reliability_diagram(logits, aleatoric, epistemic, labels):\n",
        "    \"\"\"Combined reliability diagram with uncertainty weighting\"\"\"\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    pred_classes = probs.argmax(dim=1)\n",
        "    errors = (pred_classes != labels).float()\n",
        "\n",
        "    # Flatten all data\n",
        "    prob_flat, error_flat, alea_flat, epi_flat = flatten_segmentation_data(\n",
        "        probs.max(dim=1)[0], errors, aleatoric.squeeze(), epistemic.squeeze()\n",
        "    )\n",
        "\n",
        "    total_unc = alea_flat + epi_flat\n",
        "    bin_indices = np.digitize(total_unc, np.quantile(total_unc, np.linspace(0, 1, 11)))\n",
        "\n",
        "    # Calculate metrics per bin\n",
        "    results = []\n",
        "    for i in range(10):\n",
        "        mask = bin_indices == i\n",
        "        if mask.sum() > 0:\n",
        "            bin_acc = error_flat[mask].mean()\n",
        "            bin_unc = total_unc[mask].mean()\n",
        "            results.append((bin_unc, bin_acc))\n",
        "\n",
        "    unc_vals, acc_vals = zip(*sorted(results))\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.plot(unc_vals, acc_vals, 'o-')\n",
        "    plt.plot([min(unc_vals), max(unc_vals)], [min(acc_vals), max(acc_vals)], 'k--')\n",
        "    plt.xlabel('Total Uncertainty')\n",
        "    plt.ylabel('Error Rate')\n",
        "    plt.title('Uncertainty-Weighted Reliability Diagram')\n",
        "    plt.show()\n",
        "\n",
        "def compute_calibration_metrics(logits, aleatoric, epistemic, labels):\n",
        "    \"\"\"Compute quantitative calibration metrics\"\"\"\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    pred_classes = probs.argmax(dim=1)\n",
        "    errors = (pred_classes != labels).float()\n",
        "\n",
        "    # Flatten all data\n",
        "    prob_flat, error_flat, alea_flat, epi_flat = flatten_segmentation_data(\n",
        "        probs.max(dim=1)[0], errors, aleatoric.squeeze(), epistemic.squeeze()\n",
        "    )\n",
        "\n",
        "    # Expected Calibration Error\n",
        "    def ece(uncertainties):\n",
        "        bin_indices = np.digitize(uncertainties, np.quantile(uncertainties, np.linspace(0, 1, 11)))\n",
        "        ece = 0\n",
        "        for i in range(10):\n",
        "            mask = bin_indices == i\n",
        "            if mask.sum() > 0:\n",
        "                acc = error_flat[mask].mean()\n",
        "                conf = uncertainties[mask].mean()\n",
        "                ece += np.abs(acc - conf) * mask.sum()\n",
        "        return ece / len(uncertainties)\n",
        "\n",
        "    # Brier Score\n",
        "    brier = np.mean((prob_flat - (1 - error_flat)) ** 2)\n",
        "\n",
        "    return {\n",
        "        'brier_score': brier,\n",
        "        'aleatoric_ece': ece(alea_flat),\n",
        "        'epistemic_ece': ece(epi_flat),\n",
        "        'total_ece': ece(alea_flat + epi_flat)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp7x7zVWrfwA",
        "outputId": "1758f1dd-2648-4f7d-b096-1fe5ce1f26a6"
      },
      "outputs": [],
      "source": [
        "# Compute uncertainties\n",
        "logits, aleatoric, epistemic, labels = compute_uncertainties(\n",
        "    model_unc, test_loader, device, mc_samples=50\n",
        ")\n",
        "\n",
        "# Quantitative metrics\n",
        "metrics = compute_calibration_metrics(logits, aleatoric, epistemic, labels)\n",
        "print(\"Uncalibrated Model:\\n\")\n",
        "print(\"\\nCalibration Metrics:\")\n",
        "print(f\"Brier Score: {metrics['brier_score']:.4f}\")\n",
        "print(f\"Aleatoric ECE: {metrics['aleatoric_ece']:.4f}\")\n",
        "print(f\"Epistemic ECE: {metrics['epistemic_ece']:.4f}\")\n",
        "print(f\"Total ECE: {metrics['total_ece']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZBmSFUinTvN",
        "outputId": "929996c5-d797-4844-dbc2-e87f1da44895"
      },
      "outputs": [],
      "source": [
        "logits, aleatoric, epistemic, labels = compute_uncertainties(\n",
        "        temp_scaled_model, test_loader, device, mc_samples=50)\n",
        "\n",
        "# Quantitative metrics\n",
        "metrics = compute_calibration_metrics(logits, aleatoric, epistemic, labels)\n",
        "print(\"Calibrated Model:\\n\")\n",
        "print(\"\\nCalibration Metrics:\")\n",
        "print(f\"Brier Score: {metrics['brier_score']:.4f}\")\n",
        "print(f\"Aleatoric ECE: {metrics['aleatoric_ece']:.4f}\")\n",
        "print(f\"Epistemic ECE: {metrics['epistemic_ece']:.4f}\")\n",
        "print(f\"Total ECE: {metrics['total_ece']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c0IIWiZOs4ym",
        "outputId": "2790bf8a-7d55-4ce6-d711-84b6901cf932"
      },
      "outputs": [],
      "source": [
        "plot_segmentations(temp_scaled_model, num_batches=1, double_out=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base_311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
